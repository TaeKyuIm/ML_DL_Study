{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0705c7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 30\n",
    "num_classes = 2\n",
    "learning_rate = 0.002\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e39ec69",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.manual_seed(789)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "467caab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/creditcard.csv\", sep=\",\", index_col=None)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42d7deb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>1.641931</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>-0.350151</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>1.641952</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>-0.254117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>1.641974</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>-0.081839</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>1.641974</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>-0.313249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>1.642058</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>0.514355</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "284802  1.641931 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  1.641952  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  1.641974   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  1.641974  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  1.642058  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28    Amount  \\\n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731 -0.350151   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527 -0.254117   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561 -0.081839   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533 -0.313249   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  0.514355   \n",
       "\n",
       "        Class  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Amount'] = StandardScaler().fit_transform(df['Amount'].values.reshape(-1, 1))\n",
    "df['Time'] = StandardScaler().fit_transform(df['Time'].values.reshape(-1, 1))\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd9ec829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((492, 31), (284315, 31))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomalies = df[df[\"Class\"] == 1]\n",
    "normal = df[df[\"Class\"] == 0]\n",
    "\n",
    "anomalies.shape, normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "445e785b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-1.996330</td>\n",
       "      <td>-0.752417</td>\n",
       "      <td>0.345485</td>\n",
       "      <td>2.057323</td>\n",
       "      <td>-1.468643</td>\n",
       "      <td>-1.158394</td>\n",
       "      <td>-0.077850</td>\n",
       "      <td>-0.608581</td>\n",
       "      <td>0.003603</td>\n",
       "      <td>-0.436167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499625</td>\n",
       "      <td>1.353650</td>\n",
       "      <td>-0.256573</td>\n",
       "      <td>-0.065084</td>\n",
       "      <td>-0.039124</td>\n",
       "      <td>-0.087086</td>\n",
       "      <td>-0.180998</td>\n",
       "      <td>0.129394</td>\n",
       "      <td>-0.289300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>-1.995614</td>\n",
       "      <td>1.006589</td>\n",
       "      <td>-0.071105</td>\n",
       "      <td>0.347614</td>\n",
       "      <td>1.329684</td>\n",
       "      <td>-0.193240</td>\n",
       "      <td>0.155418</td>\n",
       "      <td>0.008574</td>\n",
       "      <td>0.146538</td>\n",
       "      <td>0.103844</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020239</td>\n",
       "      <td>-0.018881</td>\n",
       "      <td>-0.120966</td>\n",
       "      <td>0.027382</td>\n",
       "      <td>0.593864</td>\n",
       "      <td>-0.334688</td>\n",
       "      <td>0.021368</td>\n",
       "      <td>0.015080</td>\n",
       "      <td>-0.081479</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>-1.994583</td>\n",
       "      <td>-0.343711</td>\n",
       "      <td>1.118615</td>\n",
       "      <td>1.293386</td>\n",
       "      <td>0.064762</td>\n",
       "      <td>0.023481</td>\n",
       "      <td>-0.992741</td>\n",
       "      <td>0.695814</td>\n",
       "      <td>-0.064809</td>\n",
       "      <td>-0.373640</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.265392</td>\n",
       "      <td>-0.700550</td>\n",
       "      <td>-0.014280</td>\n",
       "      <td>0.330615</td>\n",
       "      <td>-0.165442</td>\n",
       "      <td>0.072342</td>\n",
       "      <td>0.244882</td>\n",
       "      <td>0.098048</td>\n",
       "      <td>-0.344114</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>-1.994267</td>\n",
       "      <td>-0.591933</td>\n",
       "      <td>0.111273</td>\n",
       "      <td>0.699126</td>\n",
       "      <td>-1.536074</td>\n",
       "      <td>1.193208</td>\n",
       "      <td>0.648896</td>\n",
       "      <td>0.796706</td>\n",
       "      <td>0.016904</td>\n",
       "      <td>0.789664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205964</td>\n",
       "      <td>1.216195</td>\n",
       "      <td>0.093396</td>\n",
       "      <td>-0.900310</td>\n",
       "      <td>-0.423966</td>\n",
       "      <td>-0.607857</td>\n",
       "      <td>0.017705</td>\n",
       "      <td>-0.076746</td>\n",
       "      <td>-0.297456</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>-1.992645</td>\n",
       "      <td>0.066061</td>\n",
       "      <td>0.876263</td>\n",
       "      <td>1.093993</td>\n",
       "      <td>1.556151</td>\n",
       "      <td>-0.072318</td>\n",
       "      <td>-0.671902</td>\n",
       "      <td>0.569707</td>\n",
       "      <td>-0.143791</td>\n",
       "      <td>-0.609469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159757</td>\n",
       "      <td>0.497797</td>\n",
       "      <td>-0.043266</td>\n",
       "      <td>0.397923</td>\n",
       "      <td>-0.358151</td>\n",
       "      <td>-0.186331</td>\n",
       "      <td>0.135739</td>\n",
       "      <td>0.098840</td>\n",
       "      <td>-0.259994</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>-1.991192</td>\n",
       "      <td>-0.471796</td>\n",
       "      <td>0.523169</td>\n",
       "      <td>1.948967</td>\n",
       "      <td>0.995503</td>\n",
       "      <td>0.379069</td>\n",
       "      <td>-0.577466</td>\n",
       "      <td>0.521413</td>\n",
       "      <td>-0.128940</td>\n",
       "      <td>-0.704962</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099422</td>\n",
       "      <td>-0.287139</td>\n",
       "      <td>0.151288</td>\n",
       "      <td>0.490367</td>\n",
       "      <td>-0.725252</td>\n",
       "      <td>-0.741834</td>\n",
       "      <td>0.004784</td>\n",
       "      <td>-0.045977</td>\n",
       "      <td>-0.279465</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>-1.990224</td>\n",
       "      <td>1.073785</td>\n",
       "      <td>-0.170037</td>\n",
       "      <td>0.790656</td>\n",
       "      <td>1.128605</td>\n",
       "      <td>-0.585960</td>\n",
       "      <td>0.070807</td>\n",
       "      <td>-0.414937</td>\n",
       "      <td>0.057949</td>\n",
       "      <td>0.503324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100287</td>\n",
       "      <td>0.147604</td>\n",
       "      <td>-0.184878</td>\n",
       "      <td>-0.460811</td>\n",
       "      <td>0.423909</td>\n",
       "      <td>-0.318168</td>\n",
       "      <td>0.046111</td>\n",
       "      <td>0.046843</td>\n",
       "      <td>0.006598</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>-1.987296</td>\n",
       "      <td>-0.421336</td>\n",
       "      <td>0.845373</td>\n",
       "      <td>-0.180053</td>\n",
       "      <td>-1.194077</td>\n",
       "      <td>2.737800</td>\n",
       "      <td>3.293114</td>\n",
       "      <td>0.375299</td>\n",
       "      <td>0.660924</td>\n",
       "      <td>-0.319588</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.309462</td>\n",
       "      <td>-0.836051</td>\n",
       "      <td>-0.053805</td>\n",
       "      <td>0.940155</td>\n",
       "      <td>-0.395774</td>\n",
       "      <td>-0.006256</td>\n",
       "      <td>0.060371</td>\n",
       "      <td>-0.013897</td>\n",
       "      <td>-0.316167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>-1.986644</td>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661696</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>1.761758</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>-1.986517</td>\n",
       "      <td>-0.597236</td>\n",
       "      <td>0.897114</td>\n",
       "      <td>0.765018</td>\n",
       "      <td>-1.008934</td>\n",
       "      <td>0.491639</td>\n",
       "      <td>-0.059136</td>\n",
       "      <td>0.595702</td>\n",
       "      <td>0.110417</td>\n",
       "      <td>-0.068274</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039377</td>\n",
       "      <td>-0.208065</td>\n",
       "      <td>-0.222443</td>\n",
       "      <td>-0.842566</td>\n",
       "      <td>-0.003832</td>\n",
       "      <td>0.250814</td>\n",
       "      <td>-0.045118</td>\n",
       "      <td>0.061893</td>\n",
       "      <td>-0.313249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Time        V1        V2        V3        V4        V5        V6  \\\n",
       "15  -1.996330 -0.752417  0.345485  2.057323 -1.468643 -1.158394 -0.077850   \n",
       "70  -1.995614  1.006589 -0.071105  0.347614  1.329684 -0.193240  0.155418   \n",
       "152 -1.994583 -0.343711  1.118615  1.293386  0.064762  0.023481 -0.992741   \n",
       "172 -1.994267 -0.591933  0.111273  0.699126 -1.536074  1.193208  0.648896   \n",
       "264 -1.992645  0.066061  0.876263  1.093993  1.556151 -0.072318 -0.671902   \n",
       "346 -1.991192 -0.471796  0.523169  1.948967  0.995503  0.379069 -0.577466   \n",
       "416 -1.990224  1.073785 -0.170037  0.790656  1.128605 -0.585960  0.070807   \n",
       "588 -1.987296 -0.421336  0.845373 -0.180053 -1.194077  2.737800  3.293114   \n",
       "623 -1.986644 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823   \n",
       "628 -1.986517 -0.597236  0.897114  0.765018 -1.008934  0.491639 -0.059136   \n",
       "\n",
       "           V7        V8        V9  ...       V21       V22       V23  \\\n",
       "15  -0.608581  0.003603 -0.436167  ...  0.499625  1.353650 -0.256573   \n",
       "70   0.008574  0.146538  0.103844  ... -0.020239 -0.018881 -0.120966   \n",
       "152  0.695814 -0.064809 -0.373640  ... -0.265392 -0.700550 -0.014280   \n",
       "172  0.796706  0.016904  0.789664  ...  0.205964  1.216195  0.093396   \n",
       "264  0.569707 -0.143791 -0.609469  ...  0.159757  0.497797 -0.043266   \n",
       "346  0.521413 -0.128940 -0.704962  ... -0.099422 -0.287139  0.151288   \n",
       "416 -0.414937  0.057949  0.503324  ...  0.100287  0.147604 -0.184878   \n",
       "588  0.375299  0.660924 -0.319588  ... -0.309462 -0.836051 -0.053805   \n",
       "623  0.325574 -0.067794 -0.270953  ...  0.661696  0.435477  1.375966   \n",
       "628  0.595702  0.110417 -0.068274  ... -0.039377 -0.208065 -0.222443   \n",
       "\n",
       "          V24       V25       V26       V27       V28    Amount  Class  \n",
       "15  -0.065084 -0.039124 -0.087086 -0.180998  0.129394 -0.289300      0  \n",
       "70   0.027382  0.593864 -0.334688  0.021368  0.015080 -0.081479      0  \n",
       "152  0.330615 -0.165442  0.072342  0.244882  0.098048 -0.344114      0  \n",
       "172 -0.900310 -0.423966 -0.607857  0.017705 -0.076746 -0.297456      0  \n",
       "264  0.397923 -0.358151 -0.186331  0.135739  0.098840 -0.259994      0  \n",
       "346  0.490367 -0.725252 -0.741834  0.004784 -0.045977 -0.279465      0  \n",
       "416 -0.460811  0.423909 -0.318168  0.046111  0.046843  0.006598      0  \n",
       "588  0.940155 -0.395774 -0.006256  0.060371 -0.013897 -0.316167      0  \n",
       "623 -0.293803  0.279798 -0.145362 -0.252773  0.035764  1.761758      1  \n",
       "628 -0.842566 -0.003832  0.250814 -0.045118  0.061893 -0.313249      0  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for f in range(0, 20):\n",
    "    normal = normal.iloc[np.random.permutation(len(normal))]\n",
    "    \n",
    "\n",
    "data_set = pd.concat([normal[:10000], anomalies])\n",
    "\n",
    "x_train, x_test = train_test_split(data_set, test_size = 0.4, random_state = 42)\n",
    "\n",
    "x_train = x_train.sort_values(by=['Time'])\n",
    "x_test = x_test.sort_values(by=['Time'])\n",
    "\n",
    "y_train = x_train[\"Class\"]\n",
    "y_test = x_test[\"Class\"]\n",
    "\n",
    "x_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d030683a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "x_train:(6295, 31)\n",
      "y_train:(6295,)\n",
      "\n",
      "x_test:(4197, 31)\n",
      "y_test:(4197,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(\"Shapes:\\nx_train:%s\\ny_train:%s\\n\" % (x_train.shape, y_train.shape))\n",
    "print(\"x_test:%s\\ny_test:%s\\n\" % (x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f03ed17",
   "metadata": {},
   "source": [
    "## pytorch는 convolution 연산을 하기 위해서는 channel 차원이 중간에 오는 것이 좋음. 따라서 2차원 데이터 프레임 형태의 데이터는 (레이블 개수, 1, 데이터차원) 형태로 바꿔줘야함~!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38e20971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_torch(tensor):\n",
    "    tensor = tensor.permute(0, 2, 1)\n",
    "    tensor = F.dropout2d(tensor, 0.05)\n",
    "    tensor = tensor.permute(0, 2, 1)\n",
    "    \n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "782089a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8827, 0.9027, 0.4851,  ..., 0.0377, 0.5924, 0.6405],\n",
       "         [0.9423, 0.5575, 0.0964,  ..., 0.5745, 0.1785, 0.8549],\n",
       "         [0.4517, 0.7442, 0.6832,  ..., 0.8773, 0.3190, 0.9750],\n",
       "         ...,\n",
       "         [0.6026, 0.9154, 0.4191,  ..., 0.6926, 0.0911, 0.9612],\n",
       "         [0.6695, 0.4732, 0.9874,  ..., 0.1790, 0.6424, 0.6051],\n",
       "         [0.1841, 0.1350, 0.2721,  ..., 0.3233, 0.3503, 0.3466]],\n",
       "\n",
       "        [[0.5608, 0.7581, 0.4252,  ..., 0.9600, 0.9338, 0.4037],\n",
       "         [0.1198, 0.9453, 0.1453,  ..., 0.7804, 0.9841, 0.3979],\n",
       "         [0.6672, 0.5420, 0.1392,  ..., 0.5081, 0.2394, 0.6024],\n",
       "         ...,\n",
       "         [0.0620, 0.5377, 0.9772,  ..., 0.0231, 0.3591, 0.2685],\n",
       "         [0.9898, 0.1415, 0.7535,  ..., 0.8853, 0.4718, 0.4563],\n",
       "         [0.6761, 0.9408, 0.6521,  ..., 0.2030, 0.9845, 0.1400]],\n",
       "\n",
       "        [[0.1151, 0.1739, 0.5951,  ..., 0.0011, 0.6051, 0.2484],\n",
       "         [0.4411, 0.7450, 0.1381,  ..., 0.6807, 0.8456, 0.7403],\n",
       "         [0.8498, 0.8849, 0.7730,  ..., 0.1015, 0.0496, 0.8358],\n",
       "         ...,\n",
       "         [0.8859, 0.4700, 0.9170,  ..., 0.7066, 0.0302, 0.1918],\n",
       "         [0.7573, 0.3780, 0.6275,  ..., 0.5495, 0.0627, 0.7719],\n",
       "         [0.4928, 0.0497, 0.8110,  ..., 0.6099, 0.7091, 0.8925]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.0384, 0.8578, 0.3416,  ..., 0.0945, 0.4045, 0.7913],\n",
       "         [0.7436, 0.5798, 0.7019,  ..., 0.6905, 0.0310, 0.1146],\n",
       "         [0.0776, 0.8743, 0.1136,  ..., 0.0885, 0.7600, 0.9471],\n",
       "         ...,\n",
       "         [0.4697, 0.4884, 0.2925,  ..., 0.6666, 0.6654, 0.6921],\n",
       "         [0.7370, 0.3788, 0.8090,  ..., 0.5777, 0.1020, 0.1862],\n",
       "         [0.3695, 0.2907, 0.4631,  ..., 0.6656, 0.6092, 0.1809]],\n",
       "\n",
       "        [[0.8518, 0.3306, 0.8797,  ..., 0.0248, 0.7167, 0.1809],\n",
       "         [0.2226, 0.3455, 0.5586,  ..., 0.9107, 0.3245, 0.1556],\n",
       "         [0.2152, 0.3819, 0.3668,  ..., 0.5364, 0.5159, 0.9680],\n",
       "         ...,\n",
       "         [0.4607, 0.0337, 0.9612,  ..., 0.9578, 0.9390, 0.6932],\n",
       "         [0.2497, 0.5637, 0.1520,  ..., 0.9684, 0.1291, 0.4371],\n",
       "         [0.0529, 0.1590, 0.9487,  ..., 0.7848, 0.6737, 0.4684]],\n",
       "\n",
       "        [[0.8164, 0.7599, 0.3697,  ..., 0.2551, 0.3790, 0.7926],\n",
       "         [0.2796, 0.7043, 0.8083,  ..., 0.7438, 0.9532, 0.0830],\n",
       "         [0.7653, 0.1291, 0.2516,  ..., 0.8450, 0.0708, 0.5799],\n",
       "         ...,\n",
       "         [0.5232, 0.1363, 0.7023,  ..., 0.9770, 0.2627, 0.6883],\n",
       "         [0.2633, 0.9330, 0.9621,  ..., 0.1979, 0.1114, 0.6479],\n",
       "         [0.8093, 0.0247, 0.0502,  ..., 0.2123, 0.9662, 0.1020]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand((30, 31, 32))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de8e5db6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9291, 0.9502, 0.5106,  ..., 0.0397, 0.6236, 0.6742],\n",
       "         [0.9919, 0.5869, 0.1015,  ..., 0.6047, 0.1879, 0.8999],\n",
       "         [0.4755, 0.7834, 0.7191,  ..., 0.9235, 0.3358, 1.0263],\n",
       "         ...,\n",
       "         [0.6343, 0.9636, 0.4412,  ..., 0.7290, 0.0958, 1.0118],\n",
       "         [0.7048, 0.4981, 1.0394,  ..., 0.1885, 0.6762, 0.6370],\n",
       "         [0.1938, 0.1421, 0.2864,  ..., 0.3403, 0.3687, 0.3648]],\n",
       "\n",
       "        [[0.5904, 0.7980, 0.4476,  ..., 1.0105, 0.9830, 0.0000],\n",
       "         [0.1261, 0.9951, 0.1530,  ..., 0.8215, 1.0359, 0.0000],\n",
       "         [0.7023, 0.5705, 0.1465,  ..., 0.5348, 0.2520, 0.0000],\n",
       "         ...,\n",
       "         [0.0652, 0.5660, 1.0286,  ..., 0.0243, 0.3780, 0.0000],\n",
       "         [1.0419, 0.1490, 0.7932,  ..., 0.9319, 0.4966, 0.0000],\n",
       "         [0.7116, 0.9903, 0.6864,  ..., 0.2137, 1.0363, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.1831, 0.6264,  ..., 0.0011, 0.6370, 0.2614],\n",
       "         [0.0000, 0.7842, 0.1454,  ..., 0.7165, 0.8901, 0.7793],\n",
       "         [0.0000, 0.9315, 0.8137,  ..., 0.1068, 0.0522, 0.8798],\n",
       "         ...,\n",
       "         [0.0000, 0.4948, 0.9653,  ..., 0.7438, 0.0318, 0.2019],\n",
       "         [0.0000, 0.3979, 0.6606,  ..., 0.5785, 0.0660, 0.8125],\n",
       "         [0.0000, 0.0524, 0.8537,  ..., 0.6420, 0.7464, 0.9395]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.0404, 0.9029, 0.0000,  ..., 0.0995, 0.4258, 0.8330],\n",
       "         [0.7828, 0.6103, 0.0000,  ..., 0.7269, 0.0327, 0.1206],\n",
       "         [0.0817, 0.9203, 0.0000,  ..., 0.0931, 0.8000, 0.9970],\n",
       "         ...,\n",
       "         [0.4945, 0.5141, 0.0000,  ..., 0.7017, 0.7004, 0.7286],\n",
       "         [0.7758, 0.3988, 0.0000,  ..., 0.6081, 0.1073, 0.1960],\n",
       "         [0.3889, 0.3060, 0.0000,  ..., 0.7006, 0.6413, 0.1904]],\n",
       "\n",
       "        [[0.8966, 0.3480, 0.0000,  ..., 0.0261, 0.7544, 0.1905],\n",
       "         [0.2343, 0.3636, 0.0000,  ..., 0.9587, 0.3416, 0.1638],\n",
       "         [0.2265, 0.4020, 0.0000,  ..., 0.5647, 0.5431, 1.0189],\n",
       "         ...,\n",
       "         [0.4850, 0.0354, 0.0000,  ..., 1.0082, 0.9884, 0.7297],\n",
       "         [0.2628, 0.5934, 0.0000,  ..., 1.0194, 0.1359, 0.4601],\n",
       "         [0.0557, 0.1674, 0.0000,  ..., 0.8261, 0.7092, 0.4930]],\n",
       "\n",
       "        [[0.8594, 0.7999, 0.3892,  ..., 0.2685, 0.3990, 0.0000],\n",
       "         [0.2943, 0.7413, 0.8508,  ..., 0.7829, 1.0034, 0.0000],\n",
       "         [0.8056, 0.1359, 0.2648,  ..., 0.8895, 0.0745, 0.0000],\n",
       "         ...,\n",
       "         [0.5507, 0.1434, 0.7393,  ..., 1.0284, 0.2766, 0.0000],\n",
       "         [0.2772, 0.9821, 1.0127,  ..., 0.2083, 0.1173, 0.0000],\n",
       "         [0.8519, 0.0260, 0.0528,  ..., 0.2234, 1.0170, 0.0000]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sp = spatial_torch(x)\n",
    "x_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b040a2e",
   "metadata": {},
   "source": [
    "결과로 알 수 있듯이 특정 배치의 특정 열의 성분들이 전부 0으로 바뀜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c65d88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TCN, self).__init__()\n",
    "        \n",
    "        self.conv_1 = nn.Conv1d(1, 128, kernel_size=2, dilation=1, padding=((2-1) * 1))\n",
    "        self.conv_2 = nn.Conv1d(128, 128, kernel_size=2, dilation=2, padding=((2-1) * 2))\n",
    "        self.conv_3 = nn.Conv1d(128, 128, kernel_size=2, dilation=4, padding=((2-1) * 4))\n",
    "        self.conv_4 = nn.Conv1d(128, 128, kernel_size=2, dilation=8, padding=((2-1) * 8))\n",
    "        self.dense_1 = nn.Linear(31*128  , 128)\n",
    "        self.dense_2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = x[:, :, :-self.conv_1.padding[0]]\n",
    "        x = F.relu(x)\n",
    "        x = spatial_torch(x)\n",
    "        \n",
    "        x = self.conv_2(x)\n",
    "        x = x[:, :, :-self.conv_2.padding[0]]\n",
    "        x = F.relu(x)\n",
    "        x = spatial_torch(x)\n",
    "        \n",
    "        x = self.conv_3(x)\n",
    "        x = x[:, :, :-self.conv_3.padding[0]]\n",
    "        x = F.relu(x)\n",
    "        x = spatial_torch(x)\n",
    "        \n",
    "        \n",
    "        x = self.conv_4(x)\n",
    "        x = x[:, :, :-self.conv_4.padding[0]]\n",
    "        x = F.relu(x)\n",
    "        x = spatial_torch(x)\n",
    "        \n",
    "        \n",
    "        x = x.view(-1, 31*128)\n",
    "        x = F.relu(self.dense_1(x))\n",
    "        x = self.dense_2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d2004b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, x_train, y_train, criterion, optimizer, epoch, save_dir='TCN_CreditCard_PyTorch.ckpt'):\n",
    "    total_step = len(x_train)\n",
    "    \n",
    "    x_train = torch.Tensor(x_train).unsqueeze(1).cuda().float()\n",
    "    y_train = torch.Tensor(y_train).unsqueeze(1).cuda().long()\n",
    "\n",
    "    x_train.to(device)\n",
    "    y_train.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(x_train)\n",
    "    loss = criterion(outputs, y_train.squeeze(1))\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Epoch {}/{}, Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "\n",
    "    torch.save(model.state_dict(), save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d0e31e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def test(model, device, x_test, y_test):\n",
    "    preds = []\n",
    "    y_true = []\n",
    "    \n",
    "    # Set model to evaluation mode.\n",
    "    model.eval()  \n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        x_test = torch.Tensor(x_test).unsqueeze(1).cuda().float()\n",
    "        y_test = torch.Tensor(y_test).unsqueeze(1).cuda().long()\n",
    "        \n",
    "        x_test = x_test.to(device)\n",
    "        y_test = y_test.to(device)\n",
    "        y_test = y_test.squeeze(1)\n",
    "        outputs = model(x_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += y_test.size(0)\n",
    "        correct += (predicted == y_test).sum().item()    \n",
    "        detached_pred = predicted.detach().cpu().numpy()\n",
    "        detached_label = y_test.detach().cpu().numpy()\n",
    "        for f in range(0, len(detached_label)):\n",
    "            preds.append(detached_pred[f])\n",
    "            y_true.append(detached_label[f])\n",
    "\n",
    "        print('Test Accuracy of the model: {:.2%}'.format(correct / total))\n",
    "\n",
    "        preds = np.eye(num_classes)[preds]\n",
    "        y_true = np.eye(num_classes)[y_true]  \n",
    "        auc = roc_auc_score(np.round(preds), y_true)\n",
    "        print(\"AUC: {:.2%}\".format (auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85ee5fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 0.6946\n",
      "Epoch 2/30, Loss: 0.4355\n",
      "Epoch 3/30, Loss: 0.3351\n",
      "Epoch 4/30, Loss: 0.1899\n",
      "Epoch 5/30, Loss: 0.1272\n",
      "Epoch 6/30, Loss: 0.0872\n",
      "Epoch 7/30, Loss: 0.0638\n",
      "Epoch 8/30, Loss: 0.0696\n",
      "Epoch 9/30, Loss: 0.0686\n",
      "Epoch 10/30, Loss: 0.0709\n",
      "Epoch 11/30, Loss: 0.0640\n",
      "Epoch 12/30, Loss: 0.0528\n",
      "Epoch 13/30, Loss: 0.0460\n",
      "Epoch 14/30, Loss: 0.0434\n",
      "Epoch 15/30, Loss: 0.0540\n",
      "Epoch 16/30, Loss: 0.0445\n",
      "Epoch 17/30, Loss: 0.0394\n",
      "Epoch 18/30, Loss: 0.0413\n",
      "Epoch 19/30, Loss: 0.0395\n",
      "Epoch 20/30, Loss: 0.0406\n",
      "Epoch 21/30, Loss: 0.0395\n",
      "Epoch 22/30, Loss: 0.0395\n",
      "Epoch 23/30, Loss: 0.0402\n",
      "Epoch 24/30, Loss: 0.0369\n",
      "Epoch 25/30, Loss: 0.0388\n",
      "Epoch 26/30, Loss: 0.0369\n",
      "Epoch 27/30, Loss: 0.0367\n",
      "Epoch 28/30, Loss: 0.0382\n",
      "Epoch 29/30, Loss: 0.0371\n",
      "Epoch 30/30, Loss: 0.0363\n"
     ]
    }
   ],
   "source": [
    "model = TCN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "## Training phase\n",
    "\n",
    "for epoch in range(0, num_epochs):\n",
    "    train(model, device, x_train, y_train, criterion, optimizer, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dc96dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model: 98.98%\n",
      "AUC: 98.03%\n"
     ]
    }
   ],
   "source": [
    "test(model, device, x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
