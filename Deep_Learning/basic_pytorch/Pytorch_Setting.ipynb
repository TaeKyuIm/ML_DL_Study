{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Pytorch_Setting.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyORlZj4eqRDbJLvgm7LkJx4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":14,"metadata":{"id":"8N3Hlb1oeH1v","executionInfo":{"status":"ok","timestamp":1643103131738,"user_tz":-540,"elapsed":315,"user":{"displayName":"kyu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhZzKcSuUbALpaVk_aRw3VhUbw8RNJd-xPKSrW=s64","userId":"12287662150643412440"}}},"outputs":[],"source":["import torch\n","import torchvision\n","import torch.nn as nn # neural network 모음. (e.g. nn.Linear, nn.Conv2d, BatchNorm, Loss functions 등등)\n","import torch.optim as optim # Optimization algorithm 모음, (e.g. SGD, Adam, 등등)\n","import torch.nn.functional as F # 파라미터가 필요없는 Function 모음\n","from torch.utils.data import DataLoader # 데이터 세트 관리 및 미니 배치 생성을 위한 함수 모음\n","import torchvision.datasets as datasets # 표준 데이터 세트 모음\n","import torchvision.transforms as transforms # 데이터 세트에 적용 할 수있는 변환 관련 함수 모음\n","from torch.utils.tensorboard import SummaryWriter # tensorboard에 출력하기 위한 함수 모음\n","import torch.backends.cudnn as cudnn # cudnn을 다루기 위한 값 모음\n","\n","from torchsummary import summary # summary를 통한 model의 현황을 확인 하기 위함\n","import torch.onnx # model을 onnx 로 변환하기 위함"]},{"cell_type":"code","source":["seed = 123\n","# pytorch에서 내부적으로 사용하는 seed 값\n","torch.manual_seed(seed)\n","# cuda를 사용하는 경우\n","torch.cuda.manual_seed(seed)"],"metadata":{"id":"o8fJo5Iuec-A","executionInfo":{"status":"ok","timestamp":1643103132281,"user_tz":-540,"elapsed":17,"user":{"displayName":"kyu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhZzKcSuUbALpaVk_aRw3VhUbw8RNJd-xPKSrW=s64","userId":"12287662150643412440"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["# GPU 관련 세팅"],"metadata":{"id":"AiXvOxibeuzB"}},{"cell_type":"code","source":["# cuda 사용 가능한지 확인\n","torch.cuda.is_available()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iVPgUPxges1K","executionInfo":{"status":"ok","timestamp":1643103132282,"user_tz":-540,"elapsed":17,"user":{"displayName":"kyu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhZzKcSuUbALpaVk_aRw3VhUbw8RNJd-xPKSrW=s64","userId":"12287662150643412440"}},"outputId":"6c4a0d6d-c64b-489b-ebbf-fa60c709531d"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["# cuda가 사용 가능하면 device에 \"cuda\"를 저장하고 사용 가능하지 않으면 \"cpu\"를 저장한다.\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OO_d32ULe0_A","executionInfo":{"status":"ok","timestamp":1643103132283,"user_tz":-540,"elapsed":16,"user":{"displayName":"kyu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhZzKcSuUbALpaVk_aRw3VhUbw8RNJd-xPKSrW=s64","userId":"12287662150643412440"}},"outputId":"741f0013-081a-4fcd-842d-e7f88c8ef0b8"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["# 현재 PC의 사용가능한 GPU 사용 갯수 확인\n","torch.cuda.device_count()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nsdkx4ILe4OR","executionInfo":{"status":"ok","timestamp":1643103132283,"user_tz":-540,"elapsed":14,"user":{"displayName":"kyu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhZzKcSuUbALpaVk_aRw3VhUbw8RNJd-xPKSrW=s64","userId":"12287662150643412440"}},"outputId":"4826bfb0-d2e6-44ff-d5a3-9aeb946a0817"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["# 사용 가능한 device 갯수에 맞춰서 0번 부터 GPU 할당\n","import os\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join(list(map(str, list(range(torch.cuda.device_count())))))"],"metadata":{"id":"9_PXV6kIe-Kh","executionInfo":{"status":"ok","timestamp":1643103132283,"user_tz":-540,"elapsed":13,"user":{"displayName":"kyu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhZzKcSuUbALpaVk_aRw3VhUbw8RNJd-xPKSrW=s64","userId":"12287662150643412440"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# cudnn을 사용하도록 설정. GPU를 사용하고 있으면 기본값은 True 입니다.\n","import torch.backends.cudnn as cudnn\n","cudnn.enabled = True"],"metadata":{"id":"AeQjBR33fCu9","executionInfo":{"status":"ok","timestamp":1643103132284,"user_tz":-540,"elapsed":13,"user":{"displayName":"kyu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhZzKcSuUbALpaVk_aRw3VhUbw8RNJd-xPKSrW=s64","userId":"12287662150643412440"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["GPU device 상에서 사용가능한 메모리 확인"],"metadata":{"id":"YYE9MRGnfTue"}},{"cell_type":"code","source":["# unit : byte\n","torch.cuda.get_device_properties(\"cuda:0\").total_memory"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D6j1UwmvfIaN","executionInfo":{"status":"ok","timestamp":1643103132284,"user_tz":-540,"elapsed":13,"user":{"displayName":"kyu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhZzKcSuUbALpaVk_aRw3VhUbw8RNJd-xPKSrW=s64","userId":"12287662150643412440"}},"outputId":"6517b639-0ca6-496e-9121-e3dd18c038ce"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["17071734784"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["# unit : mega byte\n","torch.cuda.get_device_properties(\"cuda:0\").total_memory // 1e6"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NBTA07MRfX9K","executionInfo":{"status":"ok","timestamp":1643103132284,"user_tz":-540,"elapsed":11,"user":{"displayName":"kyu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhZzKcSuUbALpaVk_aRw3VhUbw8RNJd-xPKSrW=s64","userId":"12287662150643412440"}},"outputId":"933ff484-7f4e-45b6-e7d4-bfcc715aa1c5"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["17071.0"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["# unit : giga byte\n","torch.cuda.get_device_properties(\"cuda:0\").total_memory // 1e9"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ux0iwW7OfZy2","executionInfo":{"status":"ok","timestamp":1643103132286,"user_tz":-540,"elapsed":12,"user":{"displayName":"kyu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhZzKcSuUbALpaVk_aRw3VhUbw8RNJd-xPKSrW=s64","userId":"12287662150643412440"}},"outputId":"15118173-cccf-4696-b38c-0214de3d5d89"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["17.0"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["멀티 GPU사용 시 전체 사용가능한 GPU 메모리 확인하기"],"metadata":{"id":"UuXE27fdfhF-"}},{"cell_type":"code","source":["gpu_ids = list(map(str, list(range(torch.cuda.device_count()))))\n","total_gpu_memory = 0\n","for gpu_id in gpu_ids:\n","    total_gpu_memory += torch.cuda.get_device_properties(\"cuda:\" + gpu_id).total_memory"],"metadata":{"id":"XzQVCWjbfbM2","executionInfo":{"status":"ok","timestamp":1643103132286,"user_tz":-540,"elapsed":10,"user":{"displayName":"kyu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhZzKcSuUbALpaVk_aRw3VhUbw8RNJd-xPKSrW=s64","userId":"12287662150643412440"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["total_gpu_memory # byte 단위"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r--t8tawfl8j","executionInfo":{"status":"ok","timestamp":1643103132287,"user_tz":-540,"elapsed":11,"user":{"displayName":"kyu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhZzKcSuUbALpaVk_aRw3VhUbw8RNJd-xPKSrW=s64","userId":"12287662150643412440"}},"outputId":"a77eaf5a-7745-4297-c9ca-c5e4e6f3f4d9"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["17071734784"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["# 시드 고정을 위한 세팅"],"metadata":{"id":"Pn25ho0Jk-1z"}},{"cell_type":"code","source":["import numpy as np\n","import random\n","seed=1\n","torch.manual_seed(seed)\n","np.random.seed(seed)\n","random.seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","torch.backends.cudnn.benchmark = False\n","torch.backends.cudnn.deterministic = True"],"metadata":{"id":"F6Gg2Yx5lCN-","executionInfo":{"status":"ok","timestamp":1643103154710,"user_tz":-540,"elapsed":417,"user":{"displayName":"kyu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhZzKcSuUbALpaVk_aRw3VhUbw8RNJd-xPKSrW=s64","userId":"12287662150643412440"}}},"execution_count":27,"outputs":[]}]}